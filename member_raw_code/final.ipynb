{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Applications/PyCharm.app/Contents/plugins/python/helpers-pro/jupyter_debug/pydev_jupyter_utils.py\", line 64, in attach_to_debugger\n",
      "    debugger.prepare_to_run(enable_tracing_from_start=False)\n",
      "TypeError: prepare_to_run() got an unexpected keyword argument 'enable_tracing_from_start'\n",
      "Failed to connect to target debugger.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final\n"
     ]
    }
   ],
   "source": [
    "import re # for cleaning Resume_str\n",
    "import pandas as pd\n",
    "print('final')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'Resume.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['ID', 'Resume_str', 'Resume_html', 'Category'], dtype='object')"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['ID', 'Resume_str', 'Category'], dtype='object')"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['Resume_html'])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "         ID                                         Resume_str Category\n0  16852973           HR ADMINISTRATOR/MARKETING ASSOCIATE\\...       HR\n1  22323967           HR SPECIALIST, US HR OPERATIONS      ...       HR\n2  33176873           HR DIRECTOR       Summary      Over 2...       HR\n3  27018550           HR SPECIALIST       Summary    Dedica...       HR\n4  17812897           HR MANAGER         Skill Highlights  ...       HR",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Resume_str</th>\n      <th>Category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>16852973</td>\n      <td>HR ADMINISTRATOR/MARKETING ASSOCIATE\\...</td>\n      <td>HR</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>22323967</td>\n      <td>HR SPECIALIST, US HR OPERATIONS      ...</td>\n      <td>HR</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>33176873</td>\n      <td>HR DIRECTOR       Summary      Over 2...</td>\n      <td>HR</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>27018550</td>\n      <td>HR SPECIALIST       Summary    Dedica...</td>\n      <td>HR</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17812897</td>\n      <td>HR MANAGER         Skill Highlights  ...</td>\n      <td>HR</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "\"         HR ADMINISTRATOR/MARKETING ASSOCIATE\\n\\nHR ADMINISTRATOR       Summary     Dedicated Customer Service Manager with 15+ years of experience in Hospitality and Customer Service Management.   Respected builder and leader of customer-focused teams; strives to instill a shared, enthusiastic commitment to customer service.         Highlights         Focused on customer satisfaction  Team management  Marketing savvy  Conflict resolution techniques     Training and development  Skilled multi-tasker  Client relations specialist           Accomplishments      Missouri DOT Supervisor Training Certification  Certified by IHG in Customer Loyalty and Marketing by Segment   Hilton Worldwide General Manager Training Certification  Accomplished Trainer for cross server hospitality systems such as    Hilton OnQ  ,   Micros    Opera PMS   , Fidelio    OPERA    Reservation System (ORS) ,   Holidex    Completed courses and seminars in customer service, sales strategies, inventory control, loss prevention, safety, time management, leadership and performance assessment.        Experience      HR Administrator/Marketing Associate\\n\\nHR Administrator     Dec 2013   to   Current      Company Name   －   City  ,   State     Helps to develop policies, directs and coordinates activities such as employment, compensation, labor relations, benefits, training, and employee services.  Prepares employee separation notices and related documentation  Keeps records of benefits plans participation such as insurance and pension plan, personnel transactions such as hires, promotions, transfers, performance reviews, and terminations, and employee statistics for government reporting.  Advises management in appropriate resolution of employee relations issues.  Administers benefits programs such as life, health, dental, insurance, pension plans, vacation, sick leave, leave of absence, and employee assistance.     Marketing Associate \\xa0   Designed and created marketing collateral for sales meetings, trade shows and company executives.  Managed the in-house advertising program consisting of print and media collateral pieces.  Assisted in the complete design and launch of the company's website in 2 months.  Created an official company page on Facebook to facilitate interaction with customers.  Analyzed ratings and programming features of competitors to evaluate the effectiveness of marketing strategies.         Advanced Medical Claims Analyst     Mar 2012   to   Dec 2013      Company Name   －   City  ,   State     Reviewed medical bills for the accuracy of the treatments, tests, and hospital stays prior to sanctioning the claims.  Trained to interpret the codes (ICD-9, CPT) and terminology commonly used in medical billing to fully understand the paperwork that is submitted by healthcare providers.  Required to have organizational and analytical skills as well as computer skills, knowledge of medical terminology and procedures, statistics, billing standards, data analysis and laws regarding medical billing.         Assistant General Manager     Jun 2010   to   Dec 2010      Company Name   －   City  ,   State     Performed duties including but not limited to, budgeting and financial management, accounting, human resources, payroll and purchasing.  Established and maintained close working relationships with all departments of the hotel to ensure maximum operation, productivity, morale and guest service.  Handled daily operations and reported directly to the corporate office.  Hired and trained staff on overall objectives and goals with an emphasis on high customer service.  Marketing and Advertising, working on public relations with the media, government and local businesses and Chamber of Commerce.         Executive Support / Marketing Assistant     Jul 2007   to   Jun 2010      Company Name   －   City  ,   State     Provided assistance to various department heads - Executive, Marketing, Customer Service, Human Resources.  Managed front-end operations to ensure friendly and efficient transactions.  Ensured the swift resolution of customer issues to preserve customer loyalty while complying with company policies.  Exemplified the second-to-none customer service delivery in all interactions with customers and potential clients.         Reservation & Front Office Manager     Jun 2004   to   Jul 2007      Company Name   －   City  ,   State          Owner/ Partner     Dec 2001   to   May 2004      Company Name   －   City  ,   State          Price Integrity Coordinator     Aug 1999   to   Dec 2001      Company Name   －   City  ,   State          Education      N/A  ,   Business Administration   1999     Jefferson College   －   City  ,   State       Business Administration  Marketing / Advertising         High School Diploma  ,   College Prep. studies   1998     Sainte Genevieve Senior High   －   City  ,   State       Awarded American Shrubel Leadership Scholarship to Jefferson College         Skills     Accounting, ads, advertising, analytical skills, benefits, billing, budgeting, clients, Customer Service, data analysis, delivery, documentation, employee relations, financial management, government relations, Human Resources, insurance, labor relations, layout, Marketing, marketing collateral, medical billing, medical terminology, office, organizational, payroll, performance reviews, personnel, policies, posters, presentations, public relations, purchasing, reporting, statistics, website.    \""
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Resume_str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2484 entries, 0 to 2483\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   ID          2484 non-null   int64 \n",
      " 1   Resume_str  2484 non-null   object\n",
      " 2   Category    2484 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 58.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Category: 24\n",
      "Category\n",
      "ACCOUNTANT                118\n",
      "ADVOCATE                  118\n",
      "AGRICULTURE                63\n",
      "APPAREL                    97\n",
      "ARTS                      103\n",
      "AUTOMOBILE                 36\n",
      "AVIATION                  117\n",
      "BANKING                   115\n",
      "BPO                        22\n",
      "BUSINESS-DEVELOPMENT      120\n",
      "CHEF                      118\n",
      "CONSTRUCTION              112\n",
      "CONSULTANT                115\n",
      "DESIGNER                  107\n",
      "DIGITAL-MEDIA              96\n",
      "ENGINEERING               118\n",
      "FINANCE                   118\n",
      "FITNESS                   117\n",
      "HEALTHCARE                115\n",
      "HR                        110\n",
      "INFORMATION-TECHNOLOGY    120\n",
      "PUBLIC-RELATIONS          111\n",
      "SALES                     116\n",
      "TEACHER                   102\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_gb = df.groupby('Category')\n",
    "print('Number of Category: {}'.format(df_gb.ngroups))\n",
    "print(df_gb.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_spaces(s):\n",
    "    s = ' '.join(re.split('[ ]+', s.strip()))\n",
    "\n",
    "    return s\n",
    "\n",
    "# Todo:\n",
    "# add more preprocess function for preprocessor\n",
    "\n",
    "def preprocessor(df):\n",
    "    df['Resume_str'] = df['Resume_str'].apply(lambda x: clean_spaces(x))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessor(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Resume_str to a embedding (vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/737 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "109a9eb8a3494eb781cc7ce6273ba26d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/9.86k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b235d2404c3240f5b574ad51756dd38b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/653 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "514ab9cad0254b66b3df0077251a18aa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ead86b3796e5431f9a02fe518c409919"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/15.7k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f61300457b9943cdbe1cf6e328a845e2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1109570b14454ba7a44bc5710afeb825"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/349 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ea473c4389ac469bb1c2a285cebd3169"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/329M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3a34a9de4bbd41a2952113ae97a8f49d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/nq/4j2lgl093_q3fmqnpv466wc00000gn/T/ipykernel_22357/4264830266.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mSentenceTransformer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'all-distilroberta-v1'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax_seq_length\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m512\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m# Corpus with resumes\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mResume_corpus\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'Resume_str'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Note/Course/2021_fall/im5054_introduction_text_mining/term_project/project/venv/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, model_name_or_path, modules, device, cache_folder)\u001B[0m\n\u001B[1;32m     79\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexists\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     80\u001B[0m                     \u001B[0;31m# Download from hub\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 81\u001B[0;31m                     model_path_tmp = snapshot_download(model_name_or_path,\n\u001B[0m\u001B[1;32m     82\u001B[0m                                                        \u001B[0mcache_dir\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcache_folder\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     83\u001B[0m                                                        \u001B[0mlibrary_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'sentence-transformers'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Note/Course/2021_fall/im5054_introduction_text_mining/term_project/project/venv/lib/python3.9/site-packages/sentence_transformers/util.py\u001B[0m in \u001B[0;36msnapshot_download\u001B[0;34m(repo_id, revision, cache_dir, library_name, library_version, user_agent, ignore_files)\u001B[0m\n\u001B[1;32m    424\u001B[0m         \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmakedirs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnested_dirname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexist_ok\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    425\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 426\u001B[0;31m         path = cached_download(\n\u001B[0m\u001B[1;32m    427\u001B[0m             \u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    428\u001B[0m             \u001B[0mcache_dir\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstorage_folder\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Note/Course/2021_fall/im5054_introduction_text_mining/term_project/project/venv/lib/python3.9/site-packages/huggingface_hub/file_download.py\u001B[0m in \u001B[0;36mcached_download\u001B[0;34m(url, library_name, library_version, cache_dir, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, use_auth_token, local_files_only)\u001B[0m\n\u001B[1;32m    465\u001B[0m             \u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"downloading %s to %s\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtemp_file\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    466\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 467\u001B[0;31m             http_get(\n\u001B[0m\u001B[1;32m    468\u001B[0m                 \u001B[0murl_to_download\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    469\u001B[0m                 \u001B[0mtemp_file\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Note/Course/2021_fall/im5054_introduction_text_mining/term_project/project/venv/lib/python3.9/site-packages/huggingface_hub/file_download.py\u001B[0m in \u001B[0;36mhttp_get\u001B[0;34m(url, temp_file, proxies, resume_size, headers, timeout, max_retries)\u001B[0m\n\u001B[1;32m    283\u001B[0m         \u001B[0mdisable\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbool\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetEffectiveLevel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mlogging\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mNOTSET\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    284\u001B[0m     )\n\u001B[0;32m--> 285\u001B[0;31m     \u001B[0;32mfor\u001B[0m \u001B[0mchunk\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0miter_content\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mchunk_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1024\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    286\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mchunk\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# filter out keep-alive new chunks\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    287\u001B[0m             \u001B[0mprogress\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mchunk\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Note/Course/2021_fall/im5054_introduction_text_mining/term_project/project/venv/lib/python3.9/site-packages/requests/models.py\u001B[0m in \u001B[0;36mgenerate\u001B[0;34m()\u001B[0m\n\u001B[1;32m    756\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraw\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'stream'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    757\u001B[0m                 \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 758\u001B[0;31m                     \u001B[0;32mfor\u001B[0m \u001B[0mchunk\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraw\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstream\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mchunk_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdecode_content\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    759\u001B[0m                         \u001B[0;32myield\u001B[0m \u001B[0mchunk\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    760\u001B[0m                 \u001B[0;32mexcept\u001B[0m \u001B[0mProtocolError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Note/Course/2021_fall/im5054_introduction_text_mining/term_project/project/venv/lib/python3.9/site-packages/urllib3/response.py\u001B[0m in \u001B[0;36mstream\u001B[0;34m(self, amt, decode_content)\u001B[0m\n\u001B[1;32m    574\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    575\u001B[0m             \u001B[0;32mwhile\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mis_fp_closed\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_fp\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 576\u001B[0;31m                 \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mamt\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mamt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdecode_content\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdecode_content\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    577\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    578\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Note/Course/2021_fall/im5054_introduction_text_mining/term_project/project/venv/lib/python3.9/site-packages/urllib3/response.py\u001B[0m in \u001B[0;36mread\u001B[0;34m(self, amt, decode_content, cache_content)\u001B[0m\n\u001B[1;32m    510\u001B[0m         \u001B[0mfp_closed\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_fp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"closed\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    511\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 512\u001B[0;31m         \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_error_catcher\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    513\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mamt\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    514\u001B[0m                 \u001B[0;31m# cStringIO doesn't like amt=None\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/contextlib.py\u001B[0m in \u001B[0;36m__enter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    113\u001B[0m         \u001B[0;31m# do not keep args and kwds alive unnecessarily\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    114\u001B[0m         \u001B[0;31m# they are only needed for recreation, which is not possible anymore\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 115\u001B[0;31m         \u001B[0;32mdel\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    116\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    117\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgen\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('all-distilroberta-v1')\n",
    "model.max_seq_length = 512\n",
    "\n",
    "# Corpus with resumes\n",
    "Resume_corpus = df['Resume_str'].tolist()\n",
    "\n",
    "# Calculate the embeddng for every resume_str\n",
    "corpus_embeddings = model.encode(Resume_corpus)\n",
    "print(corpus_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply k-Means clustering on the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = df.groupby('Category').ngroups # 24\n",
    "clustering_model = KMeans(n_clusters=num_clusters)\n",
    "\n",
    "clustering_model.fit(corpus_embeddings)\n",
    "cluster_assignment = clustering_model.labels_ # Get the clustered label for each embedding\n",
    "print(cluster_assignment.shape)\n",
    "\n",
    "clustered_resumes = [[] for i in range(num_clusters)] # Will contain embeddings for each cluster  \n",
    "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
    "    clustered_resumes[cluster_id].append(Resume_corpus[sentence_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of resumes in each cluster')\n",
    "for i, cluster in enumerate(clustered_resumes):\n",
    "    print('Cluster {}: {}'.format(i+1, len(cluster)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo:\n",
    "# 1. Visualize the clustered result\n",
    "# 2. Try applying other clustering methods\n",
    "# 3. Other stuff that can perform on cluster, e.g. Topic modeling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the cross domain (category) resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_embeddings(df_gb, group_name):\n",
    "    print('Group name: {}'.format(group_name))\n",
    "    df_group = df_gb.get_group(group_name)\n",
    "\n",
    "    # Resume corpus of groups\n",
    "    group_corpus = df_group['Resume_str'].tolist()\n",
    "\n",
    "    group_corpus_embeddings = model.encode(group_corpus, convert_to_tensor=True)\n",
    "    print('Shape of group_corpus_embeddings: {}'.format(group_corpus_embeddings.shape))\n",
    "\n",
    "    group_avg_embedding = torch.mean(group_corpus_embeddings, dim=0, keepdim=True)\n",
    "    print('Shape of group_avg_embeddings: {}'.format(group_avg_embedding.shape))\n",
    "\n",
    "    return group_avg_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_resumeID(query_embedding, corpus_embeddings, top_k):\n",
    "    hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=top_k)\n",
    "    hits = hits[0]\n",
    "    for hit in hits:\n",
    "        print(df.ID[hit['corpus_id']], \"(Score: {:.4f})\".format(hit['score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCNT_avg_embedding = get_avg_embeddings(df_gb=df_gb, group_name='ACCOUNTANT')\n",
    "IT_avg_embedding = get_avg_embeddings(df_gb=df_gb, group_name='INFORMATION-TECHNOLOGY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = (ACCNT_avg_embedding + IT_avg_embedding) / 2\n",
    "search_resumeID(query_embedding, corpus_embeddings, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo:\n",
    "# 1. Cross 3 or more domain (categories)\n",
    "# 2. Find qualitative example (we can show in report/presentation)\n",
    "# 3. Other vector (embedding) operation to perform, i.e., other task"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd6002ba671f6b90ab33c554052cf090b1185f9b04b2f93f7d99c32c612ef541"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('torch1.7.1': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}